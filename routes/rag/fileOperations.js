const axios = require("axios");
const {
  auth,
  storage,
  PROJECT_ID,
  LOCATION,
  BUCKET_NAME
} = require("./config");
 const { pool } = require("../../config/database");
class FileOperations {
  constructor() {
    this.auth = auth;
    this.storage = storage;
    this.projectId = PROJECT_ID;
    this.location = LOCATION;
    this.bucketName = BUCKET_NAME;
    this.db = pool;
    // æ·»åŠ é€Ÿç‡é™åˆ¶
    this.lastApiCall = 0;
    this.minApiInterval = 2000; // 2ç§’é–“éš”
  }

  // æ·»åŠ é€Ÿç‡é™åˆ¶æ–¹æ³•
  async rateLimitedCall(apiCall) {
    const now = Date.now();
    const timeSinceLastCall = now - this.lastApiCall;

    if (timeSinceLastCall < this.minApiInterval) {
      const waitTime = this.minApiInterval - timeSinceLastCall;
      console.log(`Rate limiting: waiting ${waitTime}ms before API call`);
      await new Promise((resolve) => setTimeout(resolve, waitTime));
    }

    this.lastApiCall = Date.now();
    return await apiCall();
  }

  // ğŸ“¤ ä¸Šå‚³æ–‡ä»¶åˆ°æŒ‡å®šçš„ RAG Engineï¼ˆåŠ å¼· debug logï¼‰
  async uploadFileToEngine(corpusName, userId, fileBuffer, fileName) {
    try {
      const userBucketPath = `user-data/${userId}/${fileName}`;
      const bucket = this.storage.bucket(this.bucketName);
      const file = bucket.file(userBucketPath);

      console.log(`\n==== [File Upload Debug] ====`);
      console.log(`corpusName:`, corpusName);
      console.log(`userId:`, userId);
      console.log(`fileName:`, fileName);
      console.log(`fileBuffer typeof:`, typeof fileBuffer);
      console.log(`fileBuffer instanceof Buffer:`, Buffer.isBuffer(fileBuffer));
      console.log(`fileBuffer instanceof Array:`, Array.isArray(fileBuffer));

      // 1. æª¢æŸ¥ fileBuffer æ˜¯å¦ç‚º Bufferï¼Œè‹¥ä¸æ˜¯å‰‡è‡ªå‹•è½‰æ›ä¸¦è­¦å‘Š
      if (!Buffer.isBuffer(fileBuffer)) {
        console.warn(
          "[Warning] fileBuffer is not a Buffer, will convert to Buffer (may cause PDF corruption if input is not binary)"
        );
        if (typeof fileBuffer === "string") {
          fileBuffer = Buffer.from(fileBuffer, "binary");
        } else if (Array.isArray(fileBuffer)) {
          fileBuffer = Buffer.from(fileBuffer);
        } else {
          // å…¶ä»–å‹æ…‹ç›´æ¥å˜—è©¦è½‰æ›
          fileBuffer = Buffer.from(String(fileBuffer), "binary");
        }
      }

      // log bufferå…§å®¹
      if (Buffer.isBuffer(fileBuffer)) {
        console.log(
          `fileBuffer[0..15]:`,
          fileBuffer.slice(0, 16).toString("hex")
        );
        console.log(
          `fileBuffer as utf8 (first 100):`,
          fileBuffer.toString("utf8", 0, 100)
        );
      }
      console.log(`fileBuffer length:`, fileBuffer?.length);
      console.log(`fileBuffer constructor:`, fileBuffer?.constructor?.name);
      console.log(
        `ğŸ“¤ Uploading to bucket: gs://${this.bucketName}/${userBucketPath}`
      );

      // 2. æª¢æŸ¥å‰¯æª”ååˆ¤æ–·æ˜¯å¦æ­£ç¢ºæŠ“åˆ° pdf
      const ext = fileName.split(".").pop();
      if (!ext) {
        console.warn(`[Warning] fileName has no extension: ${fileName}`);
      }
      const extLower = ext.toLowerCase();
      if (extLower !== "pdf" && fileName.toLowerCase().includes("pdf")) {
        console.warn(
          `[Warning] fileName extension check: got '${extLower}', but fileName contains 'pdf'. Please check fileName: ${fileName}`
        );
      }
      let contentType = "application/octet-stream";
      if (extLower === "pdf") contentType = "application/pdf";
      if (extLower === "txt") contentType = "text/plain";
      if (extLower === "docx")
        contentType =
          "application/vnd.openxmlformats-officedocument.wordprocessingml.document";
      if (extLower === "pptx")
        contentType =
          "application/vnd.openxmlformats-officedocument.presentationml.presentation";

      console.log(`contentType:`, contentType);

      const gcsMeta = {
        contentType,
        metadata: {
          uploadedBy: userId,
          originalName: fileName,
          uploadTime: new Date().toISOString(),
        },
      };
      console.log(`GCS metadata:`, JSON.stringify(gcsMeta, null, 2));

      await file.save(fileBuffer, gcsMeta);

      const gsPath = `gs://${this.bucketName}/${userBucketPath}`;
      console.log(`âœ… File uploaded successfully to: ${gsPath}`);

      // é¡å¤–æª¢æŸ¥ GCS ä¸Šçš„ metadata
      try {
        const [meta] = await file.getMetadata();
        console.log(
          `GCS file metadata after upload:`,
          JSON.stringify(meta, null, 2)
        );
      } catch (metaErr) {
        console.warn(`âš ï¸ Failed to get GCS file metadata:`, metaErr.message);
      }

      return {
        success: true,
        userId: userId,
        fileName: fileName,
        bucketPath: gsPath,
        corpusName: corpusName,
      };
    } catch (error) {
      console.error(`âŒ Failed to upload file to engine for user ${userId}:`);
      console.error("Error details:", error.message);
      console.error("Error stack:", error.stack);
      return {
        success: false,
        error: error.message,
        stack: error.stack,
      };
    }
  }

  // ğŸ”„ å°å…¥æ–‡ä»¶åˆ°æŒ‡å®šçš„ RAG Engineï¼ˆåŠ å¼· debug logï¼‰
  async importFileToRAG(corpusName, filePath) {
    try {
      console.log(`\n==== [RAG Import Debug] ====`);
      console.log(`corpusName:`, corpusName);
      console.log(`filePath:`, filePath);
      console.log(`ğŸ”„ Importing single file: ${filePath}`);
      console.log(`ğŸ¯ Target corpus: ${corpusName}`);

      // ä½¿ç”¨å¢å¼·ç‰ˆåŠŸèƒ½å’Œ Cloud Storage é…ç½®
      const gcsConfig = this.createImportConfig("gcs", {
        uris: [filePath],
      });

      if (!gcsConfig) {
        console.error(
          `[RAG Import Debug] createImportConfig failed, gcsConfig is null`
        );
        return { success: false, error: "gcsConfig is null" };
      }

      console.log(
        `[RAG Import Debug] gcsConfig:`,
        JSON.stringify(gcsConfig, null, 2)
      );

      const importResult = await this.importFilesToRAG(corpusName, gcsConfig);
      console.log(`[RAG Import Debug] importFilesToRAG result:`, importResult);
      if (importResult && importResult.response) {
        console.log(
          `[RAG Import Debug] importFilesToRAG API response:`,
          JSON.stringify(importResult.response, null, 2)
        );
      }
      return importResult;
    } catch (error) {
      console.error(`âŒ Failed to import file ${filePath} to RAG:`);
      console.error("Error details:", {
        message: error.message,
        response: error.response?.data,
        status: error.response?.status,
        stack: error.stack,
      });

      const isQuotaError =
        error.response?.data?.error?.code === 429 ||
        error.response?.data?.error?.status === "RESOURCE_EXHAUSTED" ||
        error.response?.data?.error?.message?.includes("Quota exceeded");

      return {
        success: false,
        error: error.response?.data || error.message,
        isQuotaError: isQuotaError,
        userMessage: isQuotaError ? "ç›®å‰ç³»çµ±ç¹å¿™ï¼Œè«‹ç¨å¾Œå†è©¦" : "æ–‡ä»¶å°å…¥å¤±æ•—",
        stack: error.stack,
      };
    }
  }

  // ğŸ”„ å¢å¼·ç‰ˆï¼šæ”¯æ´å¤šç§æ•¸æ“šä¾†æºçš„æª”æ¡ˆå°å…¥åŠŸèƒ½
  // æ ¹æ“š Google å®˜æ–¹æ–‡æª”ï¼šhttps://cloud.google.com/vertex-ai/generative-ai/docs/rag/rag-data-ingestion
  // ğŸ”§ ä¿®æ­£ importFilesToRAG æ–¹æ³• - ä½¿ç”¨æ­£ç¢ºçš„ API æ ¼å¼
  async importFilesToRAG(corpusName, importConfig, importResultSink = null) {
    try {
      console.log(`ğŸ”„ Enhanced import operation to: ${corpusName}`);
      console.log(
        `ğŸ”„ Import config received:`,
        JSON.stringify(importConfig, null, 2)
      );

      const authClient = await this.auth.getClient();
      const accessToken = await authClient.getAccessToken();

      const importUrl = `https://${this.location}-aiplatform.googleapis.com/v1beta1/${corpusName}/ragFiles:import`;

      // ğŸ”§ ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¢ºçš„æœ€æ–° API æ ¼å¼
      const importRequest = {
        importRagFilesConfig: {
          gcsSource: {
            uris: importConfig.gcs_source.uris,
          },
        },
      };

      console.log(
        `ğŸ“„ Corrected import request:`,
        JSON.stringify(importRequest, null, 2)
      );
      console.log(`ğŸ“¤ Import URL: ${importUrl}`);

      // é¡å¤– log è«‹æ±‚ headers
      const reqHeaders = {
        Authorization: `Bearer ${accessToken.token}`,
        "Content-Type": "application/json",
      };
      console.log(`Import API headers:`, JSON.stringify(reqHeaders, null, 2));

      let response;
      try {
        response = await axios.post(importUrl, importRequest, {
          headers: reqHeaders,
          timeout: 60000, // è¨­ç½® 60 ç§’è¶…æ™‚
        });
      } catch (apiErr) {
        console.error(`âŒ Import API call failed:`, apiErr.message);
        if (apiErr.response) {
          console.error(
            `âŒ Import API error response:`,
            JSON.stringify(apiErr.response.data, null, 2)
          );
          console.error(`âŒ Import API error status:`, apiErr.response.status);
          console.error(
            `âŒ Import API error headers:`,
            JSON.stringify(apiErr.response.headers, null, 2)
          );
        }
        throw apiErr;
      }

      console.log(
        `âœ… Import response:`,
        JSON.stringify(response.data, null, 2)
      );

      return {
        success: true,
        status: "import_started",
        message: "æª”æ¡ˆå°å…¥æ“ä½œå·²å•Ÿå‹•",
        operationName: response.data.name,
        response: response.data,
      };
    } catch (error) {
      console.error(
        `âŒ Enhanced import failed:`,
        error.response?.data || error.message
      );
      console.error(`âŒ Import error status:`, error.response?.status);
      console.error(`âŒ Import error headers:`, error.response?.headers);
      console.error(`âŒ Import error stack:`, error.stack);

      return {
        success: false,
        error: error.response?.data?.error || error.message,
        statusCode: error.response?.status,
        userMessage: "æª”æ¡ˆå°å…¥å¤±æ•—ï¼Œä½†æ–‡ä»¶å·²æˆåŠŸä¸Šå‚³åˆ° Cloud Storage",
        stack: error.stack,
      };
    }
  }

  // ğŸ› ï¸ å‰µå»ºä¸åŒæ•¸æ“šä¾†æºçš„å°å…¥é…ç½®
  // æ ¹æ“šå®˜æ–¹æ–‡æª”æ”¯æ´: Cloud Storage, Google Drive, Slack, Jira, SharePoint
  createImportConfig(sourceType, sourceConfig) {
    const configs = {
      // Cloud Storage ä¾†æº
      gcs: {
        gcs_source: {
          uris: sourceConfig.uris || [],
        },
      },

      // Google Drive ä¾†æº
      drive: {
        google_drive_source: {
          resource_ids: sourceConfig.resourceIds || [],
        },
      },

      // Slack ä¾†æº
      slack: {
        slack_source: {
          channels: [
            {
              api_key_config: {
                api_key_secret_version: sourceConfig.apiKeySecretVersion,
              },
              channels: sourceConfig.channels || [],
            },
          ],
        },
      },

      // Jira ä¾†æº
      jira: {
        jira_source: {
          jira_queries: [
            {
              projects: sourceConfig.projects || [],
              custom_queries: sourceConfig.customQueries || [],
              email: sourceConfig.email,
              server_uri: sourceConfig.serverUri,
              api_key_config: {
                api_key_secret_version: sourceConfig.apiKeySecretVersion,
              },
            },
          ],
        },
      },

      // SharePoint ä¾†æº
      sharepoint: {
        share_point_sources: {
          share_point_source: [
            {
              client_id: sourceConfig.clientId,
              api_key_config: {
                api_key_secret_version: sourceConfig.apiKeySecretVersion,
              },
              tenant_id: sourceConfig.tenantId,
              sharepoint_site_name: sourceConfig.siteName,
              sharepoint_folder_path: sourceConfig.folderPath || "",
              drive_name: sourceConfig.driveName,
            },
          ],
        },
      },
    };

    return configs[sourceType] || null;
  }

  // ğŸ” æª¢æŸ¥å°å…¥æ“ä½œç‹€æ…‹
  async checkImportOperationStatus(operationName) {
    try {
      const authClient = await this.auth.getClient();
      const accessToken = await authClient.getAccessToken();

      // æ“ä½œç‹€æ…‹æª¢æŸ¥ URL
      const statusUrl = `https://${this.location}-aiplatform.googleapis.com/v1beta1/${operationName}`;

      console.log(`ğŸ” Checking operation status: ${statusUrl}`);

      const response = await axios.get(statusUrl, {
        headers: {
          Authorization: `Bearer ${accessToken.token}`,
          "Content-Type": "application/json",
        },
      });

      const operation = response.data;
      const isDone = operation.done || false;
      const hasError = operation.error ? true : false;

      let status = "running";
      if (isDone && hasError) {
        status = "failed";
      } else if (isDone && !hasError) {
        status = "completed";
      }

      console.log(`ğŸ“Š Operation status: ${status}, Done: ${isDone}`);

      return {
        success: true,
        operationName: operationName,
        status: status,
        done: isDone,
        error: operation.error || null,
        result: operation.response || null,
        metadata: operation.metadata || null,
        rawResponse: operation,
      };
    } catch (error) {
      console.error(`âŒ Failed to check operation status:`, error.message);
      return {
        success: false,
        error: error.response?.data || error.message,
        operationName: operationName,
      };
    }
  }

  // ğŸ“‹ ç”¨æˆ¶æ‰€æœ‰æ–‡æª”åˆ—è¡¨ï¼ˆæ”¯æ´å¤š Engineï¼Œå‰ç«¯èˆ‡æ¸¬è©¦å°ˆç”¨ï¼‰
  async getUserDocuments(corpusName) {
    try {
      const authClient = await this.auth.getClient();
      const accessToken = await authClient.getAccessToken();

      const filesUrl = `https://${this.location}-aiplatform.googleapis.com/v1beta1/${corpusName}/ragFiles`;

      console.log(`Getting documents from: ${filesUrl}`);

      const response = await axios.get(filesUrl, {
        headers: {
          Authorization: `Bearer ${accessToken.token}`,
          "Content-Type": "application/json",
        },
      });

      const files = response.data.ragFiles || [];

      // ç²å– ragId ä»¥æŸ¥è©¢æ–‡ä»¶åæ˜ å°„
      const ragId = corpusName.split("/").pop();
      const fileMapping = await this.getFileNameMapping(ragId);

      const formattedFiles = files.map((file) => {
        const ragFileId = file.name ? file.name.split("/").pop() : "unknown";
        const mappingData = fileMapping.success
          ? fileMapping.mapping[ragFileId]
          : null;
        
        const originalName = mappingData ? mappingData.filename : ragFileId;
        const createdAt = mappingData ? mappingData.created_at : null;
        
        return {
          id: ragFileId,
          name: originalName,
          uploadTime: file.uploadTime || null,
          created_at: createdAt,
          ...file,
        };
      });

      return {
        success: true,
        files: formattedFiles,
        totalFiles: formattedFiles.length,
      };
    } catch (error) {
      console.error(
        `Error getting documents from ${corpusName}:`,
        error.message
      );
      return {
        success: false,
        error: error.message,
        files: [],
      };
    }
  }

  // ğŸ—‘ï¸ æ™ºèƒ½æ–‡æª”åˆªé™¤ - è™•ç†è³‡æ–™åº«èˆ‡ RAG Engine ä¸åŒæ­¥çš„æƒ…æ³
  async deleteUserDocument(userId, ragFileId, ragId = null, canUserAccessRAG) {
    try {
      let targetRagId = ragId;

      if (!targetRagId) {
        console.log("No ragId provided, need to implement engine lookup");
        return {
          success: false,
          error: "ragId is required for document deletion",
        };
      }

      // æª¢æŸ¥ç”¨æˆ¶æ¬Šé™
      // const hasAccess = await canUserAccessRAG(userId, targetRagId);
      // if (!hasAccess) {
      //   return {
      //     success: false,
      //     error: "æ‚¨æ²’æœ‰æ¬Šé™åˆªé™¤æ­¤æ–‡æª”",
      //   };
      // }

      console.log(
        `ğŸ—‘ï¸ User ${userId} deleting document ${ragFileId} from RAG ${targetRagId}`
      );

      // ğŸ”§ ç¬¬ä¸€æ­¥ï¼šå…ˆæª¢æŸ¥è³‡æ–™åº«ä¸­æ˜¯å¦æœ‰æ­¤æª”æ¡ˆè¨˜éŒ„
      const dbCheckQuery = `
        SELECT fileid, filename FROM rag_file_name 
        WHERE ragid = ? AND fileid = ?
      `;
      const [dbFiles] = await this.db.execute(dbCheckQuery, [
        targetRagId,
        ragFileId,
      ]);

      const fileExistsInDB = dbFiles.length > 0;
      console.log(`ğŸ“‹ æª”æ¡ˆåœ¨è³‡æ–™åº«ä¸­å­˜åœ¨: ${fileExistsInDB}`);

      if (fileExistsInDB) {
        console.log(`ğŸ“„ è³‡æ–™åº«æª”æ¡ˆè¨˜éŒ„: ${dbFiles[0].filename}`);
      }

      // ğŸ”§ ç¬¬äºŒæ­¥ï¼šæª¢æŸ¥ Google RAG Engine ä¸­çš„æª”æ¡ˆ
      const authClient = await this.auth.getClient();
      const accessToken = await authClient.getAccessToken();

      const corpusName = `projects/${this.projectId}/locations/${this.location}/ragCorpora/${targetRagId}`;
      const listUrl = `https://${this.location}-aiplatform.googleapis.com/v1beta1/${corpusName}/ragFiles`;

      let actualFileId = null;
      let fileExistsInRAG = false;

      try {
        // åˆ—å‡º RAG Engine ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
        const listResponse = await axios.get(listUrl, {
          headers: {
            Authorization: `Bearer ${accessToken.token}`,
            "Content-Type": "application/json",
          },
          timeout: 30000,
        });

        const files = listResponse.data.ragFiles || [];
        console.log(`ğŸ“‹ RAG Engine ä¸­æ‰¾åˆ° ${files.length} å€‹æª”æ¡ˆ`);

        // æŸ¥æ‰¾åŒ¹é…çš„æª”æ¡ˆ
        for (const file of files) {
          const fileIdFromPath = file.name.split("/").pop();
          console.log(`ğŸ“„ æª¢æŸ¥æª”æ¡ˆ: ${fileIdFromPath} (${file.displayName})`);

          if (
            fileIdFromPath === ragFileId ||
            file.name.includes(ragFileId) ||
            ragFileId.includes(fileIdFromPath)
          ) {
            actualFileId = fileIdFromPath;
            fileExistsInRAG = true;
            console.log(`âœ… åœ¨ RAG Engine ä¸­æ‰¾åˆ°åŒ¹é…æª”æ¡ˆ: ${actualFileId}`);
            break;
          }
        }
      } catch (listError) {
        console.error(`âŒ ç„¡æ³•åˆ—å‡º RAG Engine æª”æ¡ˆ:`, listError.response?.data);
        // å¦‚æœåˆ—è¡¨æª”æ¡ˆå¤±æ•—ï¼Œæˆ‘å€‘ä»ç„¶å¯ä»¥å˜—è©¦åˆªé™¤
      }

      console.log(`ğŸ“Š æª”æ¡ˆç‹€æ…‹æª¢æŸ¥çµæœ:`);
      console.log(`   - è³‡æ–™åº«ä¸­å­˜åœ¨: ${fileExistsInDB}`);
      console.log(`   - RAG Engine ä¸­å­˜åœ¨: ${fileExistsInRAG}`);

      let ragDeleteSuccess = false;
      let dbDeleteSuccess = false;
      let gcsDeleteSuccess = false;

      // ğŸ—‘ï¸ ç¬¬ä¸‰æ­¥ï¼šå¦‚æœæª”æ¡ˆåœ¨ RAG Engine ä¸­å­˜åœ¨ï¼Œå‰‡åˆªé™¤
      if (fileExistsInRAG && actualFileId) {
        try {
          const deleteUrl = `https://${this.location}-aiplatform.googleapis.com/v1beta1/${corpusName}/ragFiles/${actualFileId}`;
          console.log(`ğŸ—‘ï¸ å¾ RAG Engine åˆªé™¤æª”æ¡ˆ: ${deleteUrl}`);

          const response = await axios.delete(deleteUrl, {
            headers: {
              Authorization: `Bearer ${accessToken.token}`,
              "Content-Type": "application/json",
            },
            timeout: 30000,
          });

          console.log(`âœ… RAG Engine åˆªé™¤æˆåŠŸ: ${response.status}`);
          ragDeleteSuccess = true;
        } catch (deleteError) {
          console.error(`âŒ RAG Engine åˆªé™¤å¤±æ•—:`, deleteError.response?.data);

          // å¦‚æœæ˜¯ 404 éŒ¯èª¤ï¼Œè¡¨ç¤ºæª”æ¡ˆå·²ç¶“ä¸å­˜åœ¨
          if (deleteError.response?.status === 404) {
            console.log(`ğŸ“ æª”æ¡ˆå·²ç¶“ä¸å­˜åœ¨æ–¼ RAG Engine ä¸­ (404)`);
            ragDeleteSuccess = true;
          }
        }
      } else {
        console.log(`ğŸ“ æª”æ¡ˆä¸å­˜åœ¨æ–¼ RAG Engine ä¸­ï¼Œè·³é RAG åˆªé™¤`);
        ragDeleteSuccess = true; // ä¸å­˜åœ¨å°±ç®—æˆåŠŸ
      }

      // ğŸ—‘ï¸ ç¬¬å››æ­¥ï¼šå¾è³‡æ–™åº«åˆªé™¤è¨˜éŒ„
      if (fileExistsInDB) {
        try {
          const deleteQuery = `DELETE FROM rag_file_name WHERE ragid = ? AND fileid = ?`;
          await this.db.execute(deleteQuery, [targetRagId, ragFileId]);
          console.log(`âœ… è³‡æ–™åº«è¨˜éŒ„åˆªé™¤æˆåŠŸ`);
          dbDeleteSuccess = true;
        } catch (dbError) {
          console.error(`âŒ è³‡æ–™åº«åˆªé™¤å¤±æ•—:`, dbError.message);
        }
      } else {
        console.log(`ğŸ“ æª”æ¡ˆä¸å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­ï¼Œè·³éè³‡æ–™åº«åˆªé™¤`);
        dbDeleteSuccess = true; // ä¸å­˜åœ¨å°±ç®—æˆåŠŸ
      }

      // ğŸ—‘ï¸ ç¬¬äº”æ­¥ï¼šå˜—è©¦å¾ Google Cloud Storage åˆªé™¤æª”æ¡ˆ
      try {
        if (fileExistsInDB && dbFiles[0].filename) {
          const originalName = dbFiles[0].filename;
          const fileExtension = originalName.split(".").pop() || "txt";
          const fileName = `user-data/${userId}/${ragFileId}.${fileExtension}`;

          const file = this.storage.bucket(this.bucketName).file(fileName);
          const [exists] = await file.exists();

          if (exists) {
            await file.delete();
            console.log(`âœ… GCS æª”æ¡ˆåˆªé™¤æˆåŠŸ: ${fileName}`);
            gcsDeleteSuccess = true;
          } else {
            console.log(`ğŸ“ GCS æª”æ¡ˆä¸å­˜åœ¨: ${fileName}`);
            gcsDeleteSuccess = true;
          }
        }
      } catch (gcsError) {
        console.log(`âš ï¸ GCS æª”æ¡ˆåˆªé™¤è­¦å‘Š:`, gcsError.message);
        gcsDeleteSuccess = true; // GCS éŒ¯èª¤ä¸æ‡‰è©²å½±éŸ¿æ•´é«”çµæœ
      }

      // ğŸ¯ åˆ¤æ–·æ•´é«”åˆªé™¤çµæœ
      const overallSuccess = ragDeleteSuccess && dbDeleteSuccess;

      if (overallSuccess) {
        return {
          success: true,
          message: "æ–‡æª”å·²æˆåŠŸåˆªé™¤",
          deletedFileId: ragFileId,
          ragId: targetRagId,
          details: {
            ragDeleted: ragDeleteSuccess,
            dbDeleted: dbDeleteSuccess,
            gcsDeleted: gcsDeleteSuccess,
            existedInRAG: fileExistsInRAG,
            existedInDB: fileExistsInDB,
          },
        };
      } else {
        return {
          success: false,
          error: "æª”æ¡ˆåˆªé™¤éƒ¨åˆ†å¤±æ•—",
          details: {
            ragDeleted: ragDeleteSuccess,
            dbDeleted: dbDeleteSuccess,
            gcsDeleted: gcsDeleteSuccess,
            existedInRAG: fileExistsInRAG,
            existedInDB: fileExistsInDB,
          },
        };
      }
    } catch (error) {
      console.error(`âŒ åˆªé™¤æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤:`, error);
      return {
        success: false,
        error: error.message,
      };
    }
  }
  async uploadToUserRAG(
    userId,
    file,
    fileName,
    ragId = null,
    createUserRAGEngine,
    getRAGEngineFromDB
  ) {
    try {
      let userEngine;

      // --- [ç¬¬ä¸€æ­¥ï¼šç¢ºå®šè¦ä½¿ç”¨çš„ RAG Engine] ---
      if (ragId) {
        // ä½¿ç”¨æŒ‡å®šçš„ RAG Engine
        console.log(`ğŸ“¤ Using specified RAG Engine: ${ragId}`);
        const engineResult = await getRAGEngineFromDB(ragId);

        if (!engineResult.success) {
          return {
            success: false,
            error: `æŒ‡å®šçš„ RAG Engine ä¸å­˜åœ¨: ${ragId}`,
          };
        }

        userEngine = {
          id: ragId,
          fullName: `projects/${this.projectId}/locations/${this.location}/ragCorpora/${ragId}`,
          displayName: engineResult.ragEngine.ragname,
          ragName: engineResult.ragEngine.ragname,
        };
      } else {
        // å¦‚æœæœªæŒ‡å®šï¼Œå‰‡æŸ¥æ‰¾æˆ–å‰µå»ºä¸€å€‹é»˜èªçš„ Engine
        console.log(`ğŸ“¤ Checking for existing RAG Engine for user: ${userId}`);
        const existingEngineQuery = `
          SELECT ragid, ragname, visibility 
          FROM rag 
          WHERE userid = ? 
          ORDER BY created_at DESC 
          LIMIT 1
        `;
        const [existingEngines] = await this.db.execute(existingEngineQuery, [
          userId,
        ]);

        if (existingEngines.length > 0) {
          const existing = existingEngines[0];
          console.log(`ğŸ“¤ Using existing RAG Engine: ${existing.ragid}`);
          userEngine = {
            id: existing.ragid,
            fullName: `projects/${this.projectId}/locations/${this.location}/ragCorpora/${existing.ragid}`,
            displayName: existing.ragname,
            ragName: existing.ragname,
          };
        } else {
          console.log(`ğŸ“¤ Creating new default RAG Engine for user: ${userId}`);
          const engineResult = await createUserRAGEngine(
            userId,
            null,
            `Default RAG for user ${userId}`,
            "private"
          );
          if (!engineResult.success) {
            return {
              success: false,
              error: engineResult.userMessage || "ç„¡æ³•å‰µå»º RAG Engine",
              details: engineResult,
            };
          }
          userEngine = {
            id: engineResult.corpusId,
            fullName: engineResult.corpusName,
            displayName: engineResult.displayName,
            ragName: engineResult.ragName,
          };
        }
      }

      console.log(
        `ğŸ“¤ Uploading to RAG Engine: ${userEngine.id} (${userEngine.displayName})`
      );

      // --- [ç¬¬äºŒæ­¥ï¼šåœ¨è³‡æ–™åº«ä¸­å‰µå»ºæª”æ¡ˆç´€éŒ„ï¼Œä¸¦ç”Ÿæˆå”¯ä¸€æª”å] ---
      let generatedFileId = null;
      try {
        const insertFileQuery = `INSERT INTO rag_file_name (ragid, filename) VALUES (?, ?)`;
        await this.db.execute(insertFileQuery, [userEngine.id, fileName]);

        const getFileQuery = `SELECT fileid FROM rag_file_name WHERE ragid = ? AND filename = ? ORDER BY created_at DESC LIMIT 1`;
        const [fileResults] = await this.db.execute(getFileQuery, [
          userEngine.id,
          fileName,
        ]);

        if (fileResults.length > 0) {
          generatedFileId = fileResults[0].fileid;
          console.log(`âœ… Generated file ID from DB: ${generatedFileId}`);
        } else {
          throw new Error(
            "Failed to get generated file ID from database after insertion."
          );
        }
      } catch (dbError) {
        console.error(
          "âŒ Database error during file record creation:",
          dbError.message
        );
        return { success: false, error: `è³‡æ–™åº«æ“ä½œå¤±æ•—: ${dbError.message}` };
      }

      const fileExtension = fileName.split(".").pop() || "tmp";
      const newFileName = `${generatedFileId}.${fileExtension}`;

      // --- [ç¬¬ä¸‰æ­¥ï¼šä¸Šå‚³æª”æ¡ˆåˆ° Google Cloud Storage] ---
      const userBucketPath = `user-data/${userId}/${newFileName}`;
      const uploadResult = await this.uploadFileToEngine(
        userEngine.fullName,
        userId,
        file.content || file.buffer || file, // ç¢ºä¿å‚³éæ­£ç¢ºçš„å…§å®¹
        newFileName
      );

      if (!uploadResult.success) {
        // å¦‚æœä¸Šå‚³ GCS å¤±æ•—ï¼Œæœ€å¥½åˆªé™¤å‰›å‰›å»ºç«‹çš„è³‡æ–™åº«ç´€éŒ„ä»¥ä¿æŒä¸€è‡´æ€§
        await this.db.execute(`DELETE FROM rag_file_name WHERE fileid = ?`, [
          generatedFileId,
        ]);
        console.log(
          `â†©ï¸ Rolled back database record for file ID: ${generatedFileId}`
        );
        return uploadResult;
      }

      // --- [ç¬¬å››æ­¥ï¼šå•Ÿå‹• Google Cloud RAG å°å…¥æ“ä½œ] ---
      const importResult = await this.importFileToRAG(
        userEngine.fullName,
        uploadResult.bucketPath
      );

      // --- [ç¬¬äº”æ­¥ï¼šã€æ ¸å¿ƒä¿®æ”¹ã€‘ç­‰å¾…ç•°æ­¥æ“ä½œå®Œæˆ] ---

      // 1. æª¢æŸ¥å°å…¥æ“ä½œæ˜¯å¦æˆåŠŸå•Ÿå‹•
      if (!importResult.success || !importResult.operationName) {
        console.error(
          "âŒ Failed to start RAG import operation:",
          importResult.error
        );
        // å¯é¸ï¼šæ¸…ç†å·²ä¸Šå‚³çš„ GCS æª”æ¡ˆå’Œè³‡æ–™åº«ç´€éŒ„
        // await this.storage.bucket(this.bucketName).file(userBucketPath).delete();
        // await this.db.execute(`DELETE FROM rag_file_name WHERE fileid = ?`, [generatedFileId]);
        return {
          success: false,
          error: "ç„¡æ³•å•Ÿå‹• RAG å¼•æ“å°å…¥æ“ä½œï¼Œä¸Šå‚³å·²å–æ¶ˆã€‚",
          details: importResult.error,
        };
      }

      // 2. ç­‰å¾…é•·æ™‚é–“é‹è¡Œçš„å°å…¥æ“ä½œå®Œæˆ (è¨­ç½® 2 åˆ†é˜è¶…æ™‚)
      console.log(
        `â³ Waiting for import operation to complete: ${importResult.operationName}`
      );
      const completionResult = await this.waitForImportCompletion(
        importResult.operationName,
        120000
      );

      // 3. æª¢æŸ¥æ“ä½œçš„æœ€çµ‚çµæœ
      if (
        !completionResult.success ||
        (completionResult.operationStatus &&
          completionResult.operationStatus.error)
      ) {
        const completionError =
          completionResult.error || completionResult.operationStatus.error;
        console.error(
          "âŒ RAG import operation failed after waiting:",
          completionError
        );
        return {
          success: false,
          error: "æª”æ¡ˆå·²ä¸Šå‚³è‡³é›²ç«¯ï¼Œä½†å°å…¥ RAG å¼•æ“æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚",
          details: completionError,
          bucketPath: uploadResult.bucketPath,
        };
      }

      // 4. å¦‚æœä¸€åˆ‡é †åˆ©ï¼Œè¡¨ç¤ºå°å…¥çœŸæ­£å®Œæˆ
      console.log(
        `âœ…âœ…âœ… File '${fileName}' successfully uploaded and imported into RAG Engine.`
      );

      // --- [ç¬¬å…­æ­¥ï¼šè¿”å›æœ€çµ‚æˆåŠŸçµæœ] ---
      return {
        success: true,
        message: "æ–‡ä»¶å·²æˆåŠŸä¸Šå‚³ä¸¦å°å…¥ RAG Engineã€‚",
        userId: userId,
        fileName: fileName,
        newFileName: newFileName,
        generatedFileId: generatedFileId,
        displayName: fileName,
        bucketPath: uploadResult.bucketPath,
        ragEngine: {
          id: userEngine.id,
          name: userEngine.fullName,
          displayName: userEngine.displayName,
          ragName: userEngine.ragName,
        },
        // è¿”å›å°å…¥å®Œæˆå¾Œçš„è©³ç´°è³‡è¨Šï¼Œè€Œéåƒ…æ˜¯å•Ÿå‹•æ™‚çš„è³‡è¨Š
        importResult: completionResult,
      };
    } catch (error) {
      console.error(
        `âŒ FATAL: An unexpected error occurred in uploadToUserRAG for user ${userId}:`
      );
      console.error("Error details:", error);
      return {
        success: false,
        error: `ä¸Šå‚³éç¨‹ä¸­ç™¼ç”Ÿæ„å¤–éŒ¯èª¤: ${error.message}`,
      };
    }
  }

  async getFileNameMapping(ragId) {
  try {
    const query = `
      SELECT fileid, filename, id, created_at
      FROM rag_file_name 
      WHERE ragid = ?
      ORDER BY created_at DESC
    `;
    const [results] = await this.db.execute(query, [ragId]);

    const mapping = {};
    results.forEach((row) => {
      // Make sure this returns an object, not a string
      mapping[row.fileid] = {
        filename: row.filename,
        created_at: row.created_at
      };
    });

    return {
      success: true,
      mapping: mapping,
      count: results.length,
    };
  } catch (error) {
    console.error("Error getting file name mapping:", error);
    return {
      success: false,
      error: error.message,
      mapping: {},
    };
  }
}

  // ğŸ”§ ä¿®å¾©çš„ importToRAG æ–¹æ³• - ä½¿ç”¨æœ€æ–°çš„ Google AI Platform API æ ¼å¼
  async importToRAG(ragId, filePath, originalFileName) {
    try {
      console.log(`ğŸ”„ === FIXED RAG FILE IMPORT ===`);
      console.log(`ğŸ“ File: ${filePath}`);
      console.log(`ğŸ†” RAG ID: ${ragId}`);

      const corpusName = `projects/${this.projectId}/locations/${this.location}/ragCorpora/${ragId}`;
      console.log(`ğŸ¯ Target corpus: ${corpusName}`);

      const authClient = await this.auth.getClient();
      const accessToken = await authClient.getAccessToken();

      // ğŸ”§ ä½¿ç”¨æ­£ç¢ºçš„ Google AI Platform RAG API æ ¼å¼ (2024å¹´æœ€æ–°ç‰ˆæœ¬)
      const importRequest = {
        importRagFilesConfig: {
          gcsSource: {
            uris: [filePath],
          },
        },
      };

      const importUrl = `https://${this.location}-aiplatform.googleapis.com/v1beta1/${corpusName}/ragFiles:import`;

      console.log(`ğŸ“¤ Import URL: ${importUrl}`);
      console.log(
        `ğŸ“„ Final import request:`,
        JSON.stringify(importRequest, null, 2)
      );

      const response = await axios.post(importUrl, importRequest, {
        headers: {
          Authorization: `Bearer ${accessToken.token}`,
          "Content-Type": "application/json",
        },
        timeout: 60000,
      });

      console.log(`âœ… Import successful:`, response.data);

      // æª¢æŸ¥æ˜¯å¦æ˜¯ç•°æ­¥æ“ä½œ
      if (response.data.name && response.data.name.includes("/operations/")) {
        console.log(`â³ Import is async operation: ${response.data.name}`);

        return {
          success: true,
          operationName: response.data.name,
          message: "æª”æ¡ˆå°å…¥å·²é–‹å§‹ï¼Œæ­£åœ¨è™•ç†ä¸­",
          isAsync: true,
        };
      } else {
        console.log(`âœ… Import completed synchronously`);
        return {
          success: true,
          response: response.data,
          message: "æª”æ¡ˆå°å…¥ Google RAG æˆåŠŸ",
          isAsync: false,
        };
      }
    } catch (error) {
      console.error(`âŒ === RAG IMPORT FAILED ===`);
      console.error(`âŒ Error Status: ${error.response?.status}`);
      console.error(`âŒ Error Data:`, error.response?.data);
      console.error(`âŒ Error Headers:`, error.response?.headers);

      // è©³ç´°éŒ¯èª¤åˆ†æ
      const errorMessage =
        error.response?.data?.error?.message || error.message;
      const errorCode =
        error.response?.data?.error?.code || error.response?.status;

      // æ ¹æ“šéŒ¯èª¤é¡å‹æä¾›æ›´å¥½çš„éŒ¯èª¤ä¿¡æ¯
      let friendlyMessage = "æª”æ¡ˆå°å…¥å¤±æ•—";
      if (errorMessage.includes("Invalid rag corpus ID")) {
        friendlyMessage = "RAG Corpus å°šæœªå°±ç·’ï¼Œè«‹ç¨å¾Œå†è©¦";
      } else if (errorMessage.includes("invalid argument")) {
        friendlyMessage = "æª”æ¡ˆæ ¼å¼æˆ–è«‹æ±‚æ ¼å¼ä¸æ­£ç¢º";
      } else if (errorMessage.includes("not found")) {
        friendlyMessage = "RAG Corpus ä¸å­˜åœ¨ï¼Œè«‹å…ˆæª¢æŸ¥ Corpus ç‹€æ…‹";
      }

      return {
        success: false,
        error: errorMessage,
        errorCode: errorCode,
        friendlyMessage: friendlyMessage,
        note: "æª”æ¡ˆå·²ä¸Šå‚³åˆ° Cloud Storageï¼Œä½† Google RAG å°å…¥å¤±æ•—",
      };
    }
  }

  // ğŸ“¥ ç›´æ¥å¾æ–‡ä»¶å…§å®¹å°å…¥åˆ° RAG Engineï¼ˆæ”¯æ´ JSON æ ¼å¼çš„æ–‡ä»¶æ•¸çµ„ï¼‰
  async importFilesFromContent(userId, ragId, files) {
    try {
      console.log(
        `ğŸ“¥ Direct import from content for user ${userId} to RAG ${ragId}`
      );
      console.log(`ğŸ“ Files to import: ${files.length}`);

      const results = [];
      const corpusName = `projects/${this.projectId}/locations/${this.location}/ragCorpora/${ragId}`;

      for (const file of files) {
        try {
          console.log(`ğŸ“„ Processing file: ${file.name}`);

          // ç¢ºä¿æ–‡ä»¶æœ‰å…§å®¹
          if (!file.content) {
            results.push({
              name: file.name,
              success: false,
              error: "File content is empty",
            });
            continue;
          }

          // è½‰æ›å…§å®¹ç‚º Buffer
          const fileBuffer = Buffer.isBuffer(file.content)
            ? file.content
            : Buffer.from(file.content, "utf-8");

          // ğŸ†• å…ˆä¿å­˜æ–‡ä»¶ååˆ°è³‡æ–™åº«ï¼Œç²å–ç”Ÿæˆçš„ fileid
          let generatedFileId = null;
          try {
            const insertFileQuery = `
              INSERT INTO rag_file_name (ragid, filename) 
              VALUES (?, ?)
            `;
            await this.db.execute(insertFileQuery, [ragId, file.name]);

            // ç²å–å‰›æ’å…¥çš„è¨˜éŒ„ä»¥å–å¾—ç”Ÿæˆçš„ fileid
            const getFileQuery = `
              SELECT fileid FROM rag_file_name 
              WHERE ragid = ? AND filename = ? 
              ORDER BY created_at DESC LIMIT 1
            `;
            const [fileResults] = await this.db.execute(getFileQuery, [
              ragId,
              file.name,
            ]);

            if (fileResults.length > 0) {
              generatedFileId = fileResults[0].fileid;
              console.log(`âœ… Generated file ID: ${generatedFileId}`);
            } else {
              throw new Error("Failed to get generated file ID");
            }
          } catch (dbError) {
            console.error(
              "âŒ Database error saving filename:",
              dbError.message
            );
            results.push({
              name: file.name,
              success: false,
              error: `Database error: ${dbError.message}`,
            });
            continue;
          }

          // ğŸ†• ä½¿ç”¨ç”Ÿæˆçš„ fileid ä½œç‚ºæ–‡ä»¶åï¼Œä¿ç•™åŸå§‹æ“´å±•å
          const fileExtension = file.name.split(".").pop() || "txt";
          const newFileName = `${generatedFileId}.${fileExtension}`;

          // ä¸Šå‚³åˆ° GCS
          const uploadResult = await this.uploadFileToEngine(
            corpusName,
            userId,
            fileBuffer,
            newFileName
          );

          if (!uploadResult.success) {
            results.push({
              name: file.name,
              success: false,
              error: uploadResult.error,
            });
            continue;
          }

          // å°å…¥åˆ° RAG Engine
          const importResult = await this.importFileToRAG(
            corpusName,
            uploadResult.bucketPath
          );

          let actualFileId = generatedFileId;
          let updateError = null;

          // ğŸ†• å¦‚æœå°å…¥æˆåŠŸä¸”æœ‰æ“ä½œåç¨±ï¼Œç­‰å¾…å®Œæˆä¸¦ç²å–å¯¦éš›æ–‡ä»¶ID
          if (importResult.success && importResult.operationName) {
            console.log(`â³ Waiting for import operation to complete...`);

            // ç­‰å¾…å°å…¥å®Œæˆ
            const completionResult = await this.waitForImportCompletion(
              importResult.operationName,
              60000 // 1åˆ†é˜è¶…æ™‚
            );

            if (completionResult.success) {
              // å˜—è©¦ç²å–å¯¦éš›çš„æ–‡ä»¶ID
              const fileIdResult = await this.getActualFileIdFromCorpus(
                corpusName,
                file.name,
                30000 // 30ç§’æ™‚é–“çª—å£
              );

              if (fileIdResult.success) {
                actualFileId = fileIdResult.fileId;
                console.log(`âœ… Got actual file ID: ${actualFileId}`);

                // ğŸ†• æ›´æ–°æ•¸æ“šåº«è¨˜éŒ„ä»¥ä½¿ç”¨å¯¦éš›çš„æ–‡ä»¶ID
                try {
                  const updateQuery = `
                    UPDATE rag_file_name 
                    SET fileid = ? 
                    WHERE ragid = ? AND fileid = ?
                  `;
                  await this.db.execute(updateQuery, [
                    actualFileId,
                    ragId,
                    generatedFileId,
                  ]);
                  console.log(`âœ… Updated database with actual file ID`);
                } catch (dbUpdateError) {
                  console.error(
                    "âŒ Failed to update file ID in database:",
                    dbUpdateError.message
                  );
                  updateError = `Database update failed: ${dbUpdateError.message}`;
                }
              } else {
                console.log(
                  `âš ï¸ Could not get actual file ID: ${fileIdResult.error}`
                );
              }
            } else {
              console.log(
                `âš ï¸ Import operation not completed: ${completionResult.error}`
              );
            }
          }

          results.push({
            name: file.name,
            success: importResult.success,
            generatedFileId: generatedFileId,
            actualFileId: actualFileId, // ğŸ†• æ·»åŠ å¯¦éš›æ–‡ä»¶ID
            newFileName: newFileName,
            bucketPath: uploadResult.bucketPath,
            importResult: importResult,
            updateError: updateError, // ğŸ†• æ·»åŠ æ›´æ–°éŒ¯èª¤ä¿¡æ¯
            error: importResult.success ? updateError : importResult.error,
          });
        } catch (fileError) {
          console.error(
            `âŒ Error processing file ${file.name}:`,
            fileError.message
          );
          results.push({
            name: file.name,
            success: false,
            error: fileError.message,
          });
        }
      }

      const successCount = results.filter((r) => r.success).length;
      const failCount = results.length - successCount;

      return {
        success: successCount > 0,
        message: `æˆåŠŸå°å…¥ ${successCount} å€‹æ–‡ä»¶ï¼Œå¤±æ•— ${failCount} å€‹`,
        results: results,
        summary: {
          total: files.length,
          success: successCount,
          failed: failCount,
        },
      };
    } catch (error) {
      console.error(`âŒ Failed to import files from content:`, error.message);
      return {
        success: false,
        error: error.message,
        results: [],
      };
    }
  }

  // ğŸ” ç­‰å¾…å°å…¥æ“ä½œå®Œæˆä¸¦ç²å–æ–‡ä»¶ID
  async waitForImportCompletion(operationName, maxWaitTime = 180000) {
    try {
      const startTime = Date.now();
      console.log(
        `â³ Waiting for import operation to complete: ${operationName}`
      );

      while (Date.now() - startTime < maxWaitTime) {
        const statusResult = await this.checkImportOperationStatus(
          operationName
        );

        if (!statusResult.success) {
          console.error(
            `âŒ Failed to check operation status:`,
            statusResult.error
          );
          return { success: false, error: statusResult.error };
        }

        if (statusResult.done) {
          if (statusResult.error) {
            console.error(`âŒ Import operation failed:`, statusResult.error);
            return { success: false, error: statusResult.error };
          }

          // æ“ä½œæˆåŠŸå®Œæˆï¼Œå˜—è©¦æå–æ–‡ä»¶ID
          if (statusResult.result && statusResult.result.ragFiles) {
            const importedFiles = statusResult.result.ragFiles;
            console.log(
              `âœ… Import completed with ${importedFiles.length} files`
            );

            return {
              success: true,
              importedFiles: importedFiles,
              operationStatus: statusResult,
            };
          } else {
            console.log(`âœ… Import completed but no file details in response`);
            return {
              success: true,
              importedFiles: [],
              operationStatus: statusResult,
            };
          }
        }

        console.log(`â³ Operation still running, waiting 5 seconds...`);
        await new Promise((resolve) => setTimeout(resolve, 5000));
      }

      // è¶…æ™‚
      console.log(`â° Import operation timed out after ${maxWaitTime}ms`);
      return {
        success: false,
        error: `Import operation timed out after ${maxWaitTime / 1000} seconds`,
        timeout: true,
      };
    } catch (error) {
      console.error(`âŒ Error waiting for import completion:`, error.message);
      return {
        success: false,
        error: error.message,
      };
    }
  }

  // ğŸ“ ç²å–å°å…¥æ–‡ä»¶çš„å¯¦éš›Google Cloudæ–‡ä»¶ID
  async getActualFileIdFromCorpus(
    corpusName,
    originalFileName,
    timeWindow = 30000
  ) {
    try {
      console.log(
        `ğŸ” Looking for file "${originalFileName}" in corpus: ${corpusName}`
      );

      const startTime = Date.now();
      while (Date.now() - startTime < timeWindow) {
        const documentsResult = await this.getUserDocuments(corpusName);

        if (documentsResult.success && documentsResult.files.length > 0) {
          // æŸ¥æ‰¾æœ€è¿‘ä¸Šå‚³çš„æ–‡ä»¶
          const sortedFiles = documentsResult.files.sort(
            (a, b) => new Date(b.uploadTime) - new Date(a.uploadTime)
          );

          // å–æœ€æ–°çš„æ–‡ä»¶ï¼Œå‡è¨­å®ƒå°±æ˜¯æˆ‘å€‘å‰›ä¸Šå‚³çš„
          const latestFile = sortedFiles[0];
          console.log(
            `ğŸ“ Found latest file: ${latestFile.id} (${latestFile.name})`
          );

          return {
            success: true,
            fileId: latestFile.id,
            fileName: latestFile.name,
            uploadTime: latestFile.uploadTime,
          };
        }

        console.log(`â³ No files found yet, waiting 3 seconds...`);
        await new Promise((resolve) => setTimeout(resolve, 3000));
      }

      console.log(`â° Could not find file within ${timeWindow / 1000} seconds`);
      return {
        success: false,
        error: `Could not find imported file within time window`,
      };
    } catch (error) {
      console.error(`âŒ Error getting actual file ID:`, error.message);
      return {
        success: false,
        error: error.message,
      };
    }
  }
}

module.exports = FileOperations;
